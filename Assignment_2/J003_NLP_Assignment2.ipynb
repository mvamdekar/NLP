{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J003_NLP_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S-3qXTtAPTEn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2022)"
      ],
      "metadata": {
        "id": "qJqvRcsJPjP4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/NLP datasets/papers.csv',error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsPqZzL4Pmqh",
        "outputId": "058ffe64-123b-4238-b93b-ccc1d5d6ec1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "YGJ5rNhxRgtx",
        "outputId": "3e374b4b-5794-4014-cf8d-f3db4d835b61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0c54d07c-c7b1-4d37-82b3-dd12c3c2645c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c54d07c-c7b1-4d37-82b3-dd12c3c2645c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c54d07c-c7b1-4d37-82b3-dd12c3c2645c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c54d07c-c7b1-4d37-82b3-dd12c3c2645c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['id','paper_text']]"
      ],
      "metadata": {
        "id": "qm9MDuuIRg4D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p50pqDUPRg7N",
        "outputId": "3b65a8b7-ba4b-4d36-dc52-438806210849"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cbcd7d60-4fcd-4e89-959e-d41403b6bf0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbcd7d60-4fcd-4e89-959e-d41403b6bf0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbcd7d60-4fcd-4e89-959e-d41403b6bf0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbcd7d60-4fcd-4e89-959e-d41403b6bf0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     id                                         paper_text\n",
              "0     1  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
              "1    10  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
              "2   100  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
              "3  1000  Bayesian Query Construction for Neural\\nNetwor...\n",
              "4  1001  Neural Network Ensembles, Cross\\nValidation, a..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdieXLKw7rYS",
        "outputId": "d4a2800e-a881-4611-e16a-11a758b062b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7241, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rHQfSGT7tMg",
        "outputId": "a89c63b6-6bde-422f-c9a9-02da272cfc92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "paper_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lem_stem(text):\n",
        "    return SnowballStemmer('english').stem(WordNetLemmatizer().lemmatize(text))"
      ],
      "metadata": {
        "id": "LeNTu8nRRg-N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(text):\n",
        "    result=[]\n",
        "    for token in simple_preprocess(text):\n",
        "        if token not in STOPWORDS and len(token)>3:\n",
        "            result.append(lem_stem(token))\n",
        "    return result"
      ],
      "metadata": {
        "id": "SE7NAyp7RhBS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "clean_df=df['paper_text'].map(process)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKrXb2f6RhEV",
        "outputId": "09ca699a-4150-4a7e-8fb6-0033d61b3cba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1lMmi0QRhH0",
        "outputId": "ddb2737f-bea9-4d3a-b2e2-ff4605d57f31"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [self, organ, associ, databas, applic, hisashi...\n",
              "1    [mean, field, theori, layer, visual, cortex, a...\n",
              "2    [store, covari, associ, long, term, potenti, d...\n",
              "3    [bayesian, queri, construct, neural, network, ...\n",
              "4    [neural, network, ensembl, cross, valid, activ...\n",
              "5    [sing, neural, instanti, deform, model, christ...\n",
              "6    [plastic, mediat, competit, learn, terrenc, se...\n",
              "7    [iceg, morpholog, classif, analogu, vlsi, neur...\n",
              "8    [real, time, control, tokamak, plasma, neural,...\n",
              "9    [real, time, control, tokamak, plasma, neural,...\n",
              "Name: paper_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary=gensim.corpora.Dictionary(clean_df)"
      ],
      "metadata": {
        "id": "YFAM5xj9SEUP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15,no_above=0.5,keep_n=100000)"
      ],
      "metadata": {
        "id": "UP6ulV_nSEW-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus=[dictionary.doc2bow(i) for i in clean_df]"
      ],
      "metadata": {
        "id": "r2TAeaJWSEZu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus[4310]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnxASkbeSEdP",
        "outputId": "6aa5b1e1-93de-4a4e-995e-d472d52d3947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (4, 1),\n",
              " (14, 1),\n",
              " (16, 3),\n",
              " (18, 1),\n",
              " (24, 2),\n",
              " (27, 1),\n",
              " (32, 2),\n",
              " (35, 1),\n",
              " (36, 1),\n",
              " (51, 1),\n",
              " (53, 1),\n",
              " (76, 1),\n",
              " (77, 3),\n",
              " (93, 2),\n",
              " (100, 1),\n",
              " (102, 2),\n",
              " (105, 1),\n",
              " (110, 1),\n",
              " (121, 1),\n",
              " (123, 3),\n",
              " (125, 4),\n",
              " (130, 1),\n",
              " (134, 3),\n",
              " (135, 2),\n",
              " (137, 6),\n",
              " (147, 5),\n",
              " (154, 1),\n",
              " (170, 2),\n",
              " (172, 1),\n",
              " (176, 1),\n",
              " (190, 1),\n",
              " (194, 1),\n",
              " (199, 1),\n",
              " (205, 18),\n",
              " (211, 1),\n",
              " (212, 1),\n",
              " (213, 2),\n",
              " (240, 2),\n",
              " (243, 2),\n",
              " (244, 4),\n",
              " (251, 1),\n",
              " (254, 1),\n",
              " (260, 1),\n",
              " (262, 4),\n",
              " (264, 1),\n",
              " (265, 7),\n",
              " (268, 1),\n",
              " (270, 1),\n",
              " (277, 7),\n",
              " (284, 1),\n",
              " (290, 2),\n",
              " (296, 2),\n",
              " (301, 4),\n",
              " (303, 4),\n",
              " (305, 1),\n",
              " (306, 1),\n",
              " (308, 4),\n",
              " (309, 1),\n",
              " (316, 37),\n",
              " (317, 2),\n",
              " (319, 5),\n",
              " (322, 18),\n",
              " (337, 5),\n",
              " (347, 1),\n",
              " (363, 1),\n",
              " (364, 1),\n",
              " (365, 1),\n",
              " (367, 2),\n",
              " (368, 3),\n",
              " (379, 1),\n",
              " (389, 1),\n",
              " (393, 1),\n",
              " (394, 3),\n",
              " (401, 6),\n",
              " (403, 4),\n",
              " (421, 1),\n",
              " (442, 4),\n",
              " (453, 1),\n",
              " (454, 3),\n",
              " (464, 1),\n",
              " (473, 1),\n",
              " (480, 1),\n",
              " (490, 1),\n",
              " (502, 2),\n",
              " (509, 1),\n",
              " (517, 1),\n",
              " (518, 1),\n",
              " (521, 3),\n",
              " (526, 1),\n",
              " (528, 2),\n",
              " (531, 1),\n",
              " (534, 1),\n",
              " (535, 4),\n",
              " (538, 1),\n",
              " (544, 3),\n",
              " (548, 2),\n",
              " (551, 2),\n",
              " (556, 1),\n",
              " (559, 40),\n",
              " (567, 1),\n",
              " (572, 3),\n",
              " (579, 1),\n",
              " (617, 2),\n",
              " (620, 6),\n",
              " (636, 2),\n",
              " (651, 2),\n",
              " (653, 1),\n",
              " (660, 3),\n",
              " (683, 3),\n",
              " (694, 5),\n",
              " (733, 4),\n",
              " (737, 2),\n",
              " (753, 1),\n",
              " (757, 1),\n",
              " (759, 1),\n",
              " (761, 1),\n",
              " (771, 1),\n",
              " (785, 2),\n",
              " (787, 7),\n",
              " (797, 1),\n",
              " (798, 1),\n",
              " (822, 21),\n",
              " (840, 7),\n",
              " (853, 2),\n",
              " (857, 3),\n",
              " (859, 1),\n",
              " (865, 1),\n",
              " (873, 27),\n",
              " (874, 1),\n",
              " (876, 1),\n",
              " (879, 5),\n",
              " (883, 4),\n",
              " (885, 1),\n",
              " (889, 1),\n",
              " (894, 2),\n",
              " (901, 4),\n",
              " (908, 1),\n",
              " (911, 2),\n",
              " (914, 1),\n",
              " (916, 2),\n",
              " (917, 1),\n",
              " (918, 1),\n",
              " (921, 2),\n",
              " (923, 1),\n",
              " (934, 1),\n",
              " (938, 1),\n",
              " (939, 3),\n",
              " (944, 1),\n",
              " (954, 1),\n",
              " (955, 1),\n",
              " (956, 2),\n",
              " (962, 7),\n",
              " (971, 1),\n",
              " (975, 1),\n",
              " (985, 1),\n",
              " (988, 1),\n",
              " (991, 4),\n",
              " (994, 1),\n",
              " (1002, 2),\n",
              " (1009, 2),\n",
              " (1013, 1),\n",
              " (1014, 3),\n",
              " (1019, 12),\n",
              " (1021, 2),\n",
              " (1023, 2),\n",
              " (1025, 13),\n",
              " (1026, 1),\n",
              " (1034, 2),\n",
              " (1040, 1),\n",
              " (1041, 9),\n",
              " (1044, 1),\n",
              " (1049, 1),\n",
              " (1053, 1),\n",
              " (1054, 1),\n",
              " (1110, 18),\n",
              " (1112, 1),\n",
              " (1129, 2),\n",
              " (1145, 2),\n",
              " (1156, 3),\n",
              " (1157, 2),\n",
              " (1165, 1),\n",
              " (1166, 1),\n",
              " (1174, 1),\n",
              " (1183, 1),\n",
              " (1193, 1),\n",
              " (1196, 2),\n",
              " (1208, 2),\n",
              " (1221, 1),\n",
              " (1224, 1),\n",
              " (1226, 4),\n",
              " (1228, 2),\n",
              " (1238, 1),\n",
              " (1242, 2),\n",
              " (1268, 1),\n",
              " (1274, 1),\n",
              " (1276, 1),\n",
              " (1283, 1),\n",
              " (1299, 31),\n",
              " (1312, 3),\n",
              " (1323, 8),\n",
              " (1334, 5),\n",
              " (1365, 2),\n",
              " (1386, 1),\n",
              " (1397, 2),\n",
              " (1412, 1),\n",
              " (1430, 3),\n",
              " (1441, 2),\n",
              " (1449, 4),\n",
              " (1453, 1),\n",
              " (1454, 1),\n",
              " (1458, 1),\n",
              " (1460, 2),\n",
              " (1480, 1),\n",
              " (1481, 1),\n",
              " (1508, 1),\n",
              " (1520, 2),\n",
              " (1557, 1),\n",
              " (1559, 1),\n",
              " (1563, 1),\n",
              " (1570, 2),\n",
              " (1595, 1),\n",
              " (1616, 1),\n",
              " (1633, 1),\n",
              " (1637, 1),\n",
              " (1647, 1),\n",
              " (1662, 3),\n",
              " (1676, 7),\n",
              " (1679, 1),\n",
              " (1701, 1),\n",
              " (1708, 3),\n",
              " (1737, 1),\n",
              " (1762, 1),\n",
              " (1765, 1),\n",
              " (1784, 2),\n",
              " (1789, 1),\n",
              " (1800, 1),\n",
              " (1811, 1),\n",
              " (1820, 2),\n",
              " (1823, 24),\n",
              " (1825, 2),\n",
              " (1844, 1),\n",
              " (1866, 1),\n",
              " (1873, 1),\n",
              " (1880, 1),\n",
              " (1882, 1),\n",
              " (1948, 1),\n",
              " (2010, 2),\n",
              " (2068, 1),\n",
              " (2069, 1),\n",
              " (2090, 1),\n",
              " (2112, 2),\n",
              " (2113, 1),\n",
              " (2120, 1),\n",
              " (2173, 2),\n",
              " (2202, 1),\n",
              " (2240, 2),\n",
              " (2248, 1),\n",
              " (2256, 2),\n",
              " (2277, 3),\n",
              " (2314, 1),\n",
              " (2330, 1),\n",
              " (2398, 1),\n",
              " (2404, 1),\n",
              " (2406, 1),\n",
              " (2426, 2),\n",
              " (2427, 1),\n",
              " (2480, 2),\n",
              " (2503, 5),\n",
              " (2520, 3),\n",
              " (2580, 3),\n",
              " (2582, 1),\n",
              " (2590, 1),\n",
              " (2620, 1),\n",
              " (2659, 1),\n",
              " (2675, 1),\n",
              " (2676, 5),\n",
              " (2691, 1),\n",
              " (2699, 1),\n",
              " (2701, 5),\n",
              " (2727, 2),\n",
              " (2742, 1),\n",
              " (2781, 2),\n",
              " (2805, 1),\n",
              " (2811, 2),\n",
              " (2822, 2),\n",
              " (2826, 1),\n",
              " (2840, 21),\n",
              " (2844, 1),\n",
              " (2855, 4),\n",
              " (2857, 2),\n",
              " (2872, 1),\n",
              " (2886, 2),\n",
              " (2971, 2),\n",
              " (2983, 1),\n",
              " (3026, 3),\n",
              " (3054, 1),\n",
              " (3057, 3),\n",
              " (3066, 1),\n",
              " (3083, 1),\n",
              " (3086, 1),\n",
              " (3135, 1),\n",
              " (3142, 6),\n",
              " (3147, 1),\n",
              " (3148, 1),\n",
              " (3181, 1),\n",
              " (3195, 1),\n",
              " (3333, 1),\n",
              " (3384, 2),\n",
              " (3461, 1),\n",
              " (3473, 1),\n",
              " (3489, 1),\n",
              " (3499, 1),\n",
              " (3549, 1),\n",
              " (3565, 1),\n",
              " (3568, 1),\n",
              " (3611, 1),\n",
              " (3617, 9),\n",
              " (3659, 1),\n",
              " (3676, 1),\n",
              " (3695, 8),\n",
              " (3865, 1),\n",
              " (3869, 2),\n",
              " (3874, 1),\n",
              " (3945, 1),\n",
              " (3990, 1),\n",
              " (4096, 1),\n",
              " (4172, 1),\n",
              " (4330, 1),\n",
              " (4401, 1),\n",
              " (4456, 1),\n",
              " (4471, 1),\n",
              " (4525, 1),\n",
              " (4636, 9),\n",
              " (4701, 1),\n",
              " (4739, 1),\n",
              " (4848, 2),\n",
              " (5104, 1),\n",
              " (5305, 1),\n",
              " (5308, 1),\n",
              " (5313, 1),\n",
              " (5314, 1),\n",
              " (5319, 1),\n",
              " (5675, 3),\n",
              " (6072, 2),\n",
              " (6158, 1),\n",
              " (6161, 1),\n",
              " (6278, 1),\n",
              " (6334, 1),\n",
              " (6388, 1),\n",
              " (6447, 1),\n",
              " (6469, 1),\n",
              " (6554, 3),\n",
              " (6561, 2),\n",
              " (6578, 1),\n",
              " (6651, 1),\n",
              " (6852, 5),\n",
              " (6941, 3),\n",
              " (7120, 1),\n",
              " (7172, 1),\n",
              " (7463, 1),\n",
              " (7472, 1),\n",
              " (7596, 3),\n",
              " (7605, 1),\n",
              " (7802, 1),\n",
              " (7842, 1),\n",
              " (7847, 2),\n",
              " (8107, 1),\n",
              " (8252, 1),\n",
              " (8468, 8),\n",
              " (8652, 1),\n",
              " (8710, 2),\n",
              " (8909, 1),\n",
              " (8937, 1),\n",
              " (9016, 2),\n",
              " (9017, 1),\n",
              " (9086, 1),\n",
              " (9219, 1),\n",
              " (9293, 1),\n",
              " (9294, 1),\n",
              " (9502, 1),\n",
              " (9664, 1),\n",
              " (9748, 2),\n",
              " (9799, 2),\n",
              " (10014, 1),\n",
              " (10047, 1),\n",
              " (10059, 1),\n",
              " (10347, 1),\n",
              " (10381, 1),\n",
              " (10397, 1),\n",
              " (10476, 1),\n",
              " (10573, 1),\n",
              " (10626, 1),\n",
              " (10732, 1),\n",
              " (10975, 12)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora,models"
      ],
      "metadata": {
        "id": "eQVMFYLSSEg2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=models.TfidfModel(bow_corpus)"
      ],
      "metadata": {
        "id": "RoUaB8hrSToj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tfidf=tfidf[bow_corpus]"
      ],
      "metadata": {
        "id": "WAVKyvEfSTrc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "metadata": {
        "id": "BqJaHqMwSTu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a776de6-25e1-42df-da3f-d582b60523ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.04641498364526951),\n",
            " (1, 0.016180935748663635),\n",
            " (2, 0.030941689773980735),\n",
            " (3, 0.018410338822421806),\n",
            " (4, 0.02044348103201744),\n",
            " (5, 0.01375843310177131),\n",
            " (6, 0.016580197020705605),\n",
            " (7, 0.012630296856504426),\n",
            " (8, 0.013345574293887243),\n",
            " (9, 0.02458912052166688),\n",
            " (10, 0.010078657302783572),\n",
            " (11, 0.016329357413836454),\n",
            " (12, 0.02659666249110095),\n",
            " (13, 0.028467924504446716),\n",
            " (14, 0.006837731608066944),\n",
            " (15, 0.007348096823887533),\n",
            " (16, 0.014472960566842557),\n",
            " (17, 0.019345666070698684),\n",
            " (18, 0.06133744909981713),\n",
            " (19, 0.04685736211024454),\n",
            " (20, 0.010161644995211763),\n",
            " (21, 0.018561756307282903),\n",
            " (22, 0.016525757058043263),\n",
            " (23, 0.01401533064242998),\n",
            " (24, 0.010756014939245386),\n",
            " (25, 0.0075779725849975),\n",
            " (26, 0.027740048647153844),\n",
            " (27, 0.049795287314366325),\n",
            " (28, 0.016648336398781927),\n",
            " (29, 0.07564241895346906),\n",
            " (30, 0.009846338226125758),\n",
            " (31, 0.1137507489750968),\n",
            " (32, 0.03199582552906563),\n",
            " (33, 0.013770692378516088),\n",
            " (34, 0.011631751383955826),\n",
            " (35, 0.021430980953547542),\n",
            " (36, 0.11451399345719121),\n",
            " (37, 0.0774171766905939),\n",
            " (38, 0.023425413023210877),\n",
            " (39, 0.020796121772866077),\n",
            " (40, 0.03226616439235617),\n",
            " (41, 0.024470361835282586),\n",
            " (42, 0.0073040282856693985),\n",
            " (43, 0.023165236722228148),\n",
            " (44, 0.25342192224026217),\n",
            " (45, 0.05603460883126851),\n",
            " (46, 0.016830029752567643),\n",
            " (47, 0.029751392478429284),\n",
            " (48, 0.031667964233606925),\n",
            " (49, 0.013582982706071686),\n",
            " (50, 0.007154428342005901),\n",
            " (51, 0.020875016606033223),\n",
            " (52, 0.059059492785417),\n",
            " (53, 0.014996536416776922),\n",
            " (54, 0.027255004604922188),\n",
            " (55, 0.017631897469754645),\n",
            " (56, 0.02605162669387783),\n",
            " (57, 0.008440981388190195),\n",
            " (58, 0.031232696027390292),\n",
            " (59, 0.03332516353341918),\n",
            " (60, 0.02071763030777255),\n",
            " (61, 0.007140970651057846),\n",
            " (62, 0.06295683117920021),\n",
            " (63, 0.017880532489673615),\n",
            " (64, 0.06853807644213185),\n",
            " (65, 0.029113263652480285),\n",
            " (66, 0.06448255485073938),\n",
            " (67, 0.047326567347708674),\n",
            " (68, 0.022977903665488606),\n",
            " (69, 0.052989758230061114),\n",
            " (70, 0.01418035499988457),\n",
            " (71, 0.008933483145266622),\n",
            " (72, 0.01930841206420031),\n",
            " (73, 0.024462032015582027),\n",
            " (74, 0.14347819281611401),\n",
            " (75, 0.02173764995599897),\n",
            " (76, 0.007666686811838701),\n",
            " (77, 0.02558198721601355),\n",
            " (78, 0.04833054600031651),\n",
            " (79, 0.013638819136652528),\n",
            " (80, 0.011960515600202058),\n",
            " (81, 0.023851012841532595),\n",
            " (82, 0.029209506871772293),\n",
            " (83, 0.00847924854211587),\n",
            " (84, 0.038056924198546616),\n",
            " (85, 0.031293398425736245),\n",
            " (86, 0.24070438912306832),\n",
            " (87, 0.013150226231999285),\n",
            " (88, 0.013027244154942153),\n",
            " (89, 0.07611384839709323),\n",
            " (90, 0.03431056976397554),\n",
            " (91, 0.03819481648428513),\n",
            " (92, 0.04804210848249543),\n",
            " (93, 0.01467411228564477),\n",
            " (94, 0.009255360516611381),\n",
            " (95, 0.006750307572896785),\n",
            " (96, 0.017573344419582367),\n",
            " (97, 0.03314327357848812),\n",
            " (98, 0.007106089777496567),\n",
            " (99, 0.009199021660996263),\n",
            " (100, 0.014410795444559752),\n",
            " (101, 0.024068829183777507),\n",
            " (102, 0.013322664055362322),\n",
            " (103, 0.024563535321129867),\n",
            " (104, 0.012885896353091262),\n",
            " (105, 0.010611505772420735),\n",
            " (106, 0.044636132610458575),\n",
            " (107, 0.03093612655964698),\n",
            " (108, 0.031354580689917005),\n",
            " (109, 0.02344714626589315),\n",
            " (110, 0.008657101944435908),\n",
            " (111, 0.006648704326863557),\n",
            " (112, 0.04210293835157814),\n",
            " (113, 0.05798214898448388),\n",
            " (114, 0.017580180441519728),\n",
            " (115, 0.02418957291372838),\n",
            " (116, 0.009209554004804733),\n",
            " (117, 0.047326567347708674),\n",
            " (118, 0.06981774789982173),\n",
            " (119, 0.025919375356223642),\n",
            " (120, 0.010375134645677046),\n",
            " (121, 0.008289777241063702),\n",
            " (122, 0.059330467865016584),\n",
            " (123, 0.02825423300396953),\n",
            " (124, 0.018910604738367264),\n",
            " (125, 0.06567114249444816),\n",
            " (126, 0.0219084849709991),\n",
            " (127, 0.020702497452368674),\n",
            " (128, 0.016444808446752723),\n",
            " (129, 0.0054711695839146195),\n",
            " (130, 0.012478749041653529),\n",
            " (131, 0.018692233998648517),\n",
            " (132, 0.02762538705198685),\n",
            " (133, 0.014417678073838746),\n",
            " (134, 0.006991821884537586),\n",
            " (135, 0.009576458505110628),\n",
            " (136, 0.019907773165239045),\n",
            " (137, 0.03676811538128344),\n",
            " (138, 0.016224294495758292),\n",
            " (139, 0.03612811456336562),\n",
            " (140, 0.01585911519424252),\n",
            " (141, 0.01845427964989153),\n",
            " (142, 0.033106729163341855),\n",
            " (143, 0.0230000604355161),\n",
            " (144, 0.012923440579979597),\n",
            " (145, 0.0327656613166855),\n",
            " (146, 0.039786529104962796),\n",
            " (147, 0.022931085863165373),\n",
            " (148, 0.04063190574156002),\n",
            " (149, 0.019511661820822816),\n",
            " (150, 0.01055277745507229),\n",
            " (151, 0.006732430444737371),\n",
            " (152, 0.025919375356223642),\n",
            " (153, 0.040442881330888074),\n",
            " (154, 0.008789066200536598),\n",
            " (155, 0.06435305035118268),\n",
            " (156, 0.04094654978038202),\n",
            " (157, 0.04194152883658442),\n",
            " (158, 0.02511913232847311),\n",
            " (159, 0.028637206406713373),\n",
            " (160, 0.04522193197473524),\n",
            " (161, 0.02620798587271176),\n",
            " (162, 0.01606080780975109),\n",
            " (163, 0.026303340460167458),\n",
            " (164, 0.00956541519843673),\n",
            " (165, 0.011679942798153606),\n",
            " (166, 0.13098846466306807),\n",
            " (167, 0.02331300704512283),\n",
            " (168, 0.14681578813878157),\n",
            " (169, 0.027291255332152084),\n",
            " (170, 0.00664365900979168),\n",
            " (171, 0.02421452932616025),\n",
            " (172, 0.012267273696315188),\n",
            " (173, 0.018410338822421806),\n",
            " (174, 0.03645591184725241),\n",
            " (175, 0.031293398425736245),\n",
            " (176, 0.03442444717896831),\n",
            " (177, 0.01672727063620114),\n",
            " (178, 0.008013993333012004),\n",
            " (179, 0.02322946544034085),\n",
            " (180, 0.01374539981968559),\n",
            " (181, 0.01927592229366988),\n",
            " (182, 0.02686706610260949),\n",
            " (183, 0.009405231348455678),\n",
            " (184, 0.021806547490667218),\n",
            " (185, 0.00780023016299763),\n",
            " (186, 0.02487628559426228),\n",
            " (187, 0.04559954423653786),\n",
            " (188, 0.025202208113721477),\n",
            " (189, 0.025173387666979304),\n",
            " (190, 0.011453506521260193),\n",
            " (191, 0.03722689568820158),\n",
            " (192, 0.006866228603360115),\n",
            " (193, 0.014733907467329504),\n",
            " (194, 0.013144382882447138),\n",
            " (195, 0.02859408921378031),\n",
            " (196, 0.08683783797160823),\n",
            " (197, 0.017305114741217993),\n",
            " (198, 0.008110927874367018),\n",
            " (199, 0.19456984870104266),\n",
            " (200, 0.007367455995245939),\n",
            " (201, 0.008524134014070362),\n",
            " (202, 0.02105146917578907),\n",
            " (203, 0.005702151397043387),\n",
            " (204, 0.015199527105417865),\n",
            " (205, 0.006994460206061063),\n",
            " (206, 0.0688021829043896),\n",
            " (207, 0.020938716686727997),\n",
            " (208, 0.019884583599511056),\n",
            " (209, 0.03421533479489052),\n",
            " (210, 0.02477207574527468),\n",
            " (211, 0.013262096423280769),\n",
            " (212, 0.014062982908576186),\n",
            " (213, 0.006889622624539601),\n",
            " (214, 0.031541084078675334),\n",
            " (215, 0.03082109357388534),\n",
            " (216, 0.03224127742536969),\n",
            " (217, 0.13348479999943777),\n",
            " (218, 0.01438332597077504),\n",
            " (219, 0.08030403904875545),\n",
            " (220, 0.059602973217489495),\n",
            " (221, 0.023564264344633955),\n",
            " (222, 0.07415307048491714),\n",
            " (223, 0.06974059337931787),\n",
            " (224, 0.04959381049188654),\n",
            " (225, 0.0076551825122635085),\n",
            " (226, 0.007803159024381373),\n",
            " (227, 0.012179117450778607),\n",
            " (228, 0.006042229073374155),\n",
            " (229, 0.03886456294500761),\n",
            " (230, 0.0699758501524303),\n",
            " (231, 0.02495648855151167),\n",
            " (232, 0.014668596863449108),\n",
            " (233, 0.01115661385900725),\n",
            " (234, 0.18904126658287657),\n",
            " (235, 0.009333502233420209),\n",
            " (236, 0.06471463683207924),\n",
            " (237, 0.10465512187802102),\n",
            " (238, 0.014591763598385226),\n",
            " (239, 0.0890357088627535),\n",
            " (240, 0.005408571008851649),\n",
            " (241, 0.023949940269735723),\n",
            " (242, 0.010000440203367676),\n",
            " (243, 0.008113976728499091),\n",
            " (244, 0.014791504132134491),\n",
            " (245, 0.03684303936303956),\n",
            " (246, 0.04054584222525922),\n",
            " (247, 0.017456577816068183),\n",
            " (248, 0.027655809335631158),\n",
            " (249, 0.01143256166624225),\n",
            " (250, 0.01776559702040225),\n",
            " (251, 0.011284166158113139),\n",
            " (252, 0.04559954423653786),\n",
            " (253, 0.03345921606289044),\n",
            " (254, 0.021422911953173536),\n",
            " (255, 0.0211330243678832),\n",
            " (256, 0.03518057413567203),\n",
            " (257, 0.013969563659505949),\n",
            " (258, 0.007989948215064187),\n",
            " (259, 0.025513528611653694),\n",
            " (260, 0.016329136575476595),\n",
            " (261, 0.006506186192722136),\n",
            " (262, 0.013608376123632434),\n",
            " (263, 0.0108901670256658),\n",
            " (264, 0.05335832654759435),\n",
            " (265, 0.009488550136095323),\n",
            " (266, 0.014254161087822678),\n",
            " (267, 0.03826166079374692),\n",
            " (268, 0.012468036906913438),\n",
            " (269, 0.017779321281676305),\n",
            " (270, 0.009751559719686862),\n",
            " (271, 0.06340329734106522),\n",
            " (272, 0.03402160220054985),\n",
            " (273, 0.05078836478544026),\n",
            " (274, 0.10629014769218381),\n",
            " (275, 0.08168408335530147),\n",
            " (276, 0.025173387666979304),\n",
            " (277, 0.07090177499942285),\n",
            " (278, 0.02096411692103243),\n",
            " (279, 0.11375298774246272),\n",
            " (280, 0.019754807977817174),\n",
            " (281, 0.015402605340556562),\n",
            " (282, 0.015976129545860192),\n",
            " (283, 0.0745492047378013),\n",
            " (284, 0.008601691400766259),\n",
            " (285, 0.010586281906158585),\n",
            " (286, 0.009853970885634089),\n",
            " (287, 0.036866883745507534),\n",
            " (288, 0.024666387547257435),\n",
            " (289, 0.4720322147835124),\n",
            " (290, 0.01982291406682984),\n",
            " (291, 0.04246106992192818),\n",
            " (292, 0.011098100227873702),\n",
            " (293, 0.14384143439021488),\n",
            " (294, 0.04294273614329879),\n",
            " (295, 0.02262984401336354),\n",
            " (296, 0.0073012823157579685),\n",
            " (297, 0.06481123781209504),\n",
            " (298, 0.088591102540719),\n",
            " (299, 0.035473681296149785),\n",
            " (300, 0.028888280240200768),\n",
            " (301, 0.14375699909245737),\n",
            " (302, 0.015682670857328898),\n",
            " (303, 0.022365199777677036),\n",
            " (304, 0.012581260687521231),\n",
            " (305, 0.01591740122851175),\n",
            " (306, 0.010306013212275866),\n",
            " (307, 0.0789945315813156),\n",
            " (308, 0.008178281683355612),\n",
            " (309, 0.018561756307282903),\n",
            " (310, 0.04246144049859854),\n",
            " (311, 0.0400438115900541),\n",
            " (312, 0.01013784328671134),\n",
            " (313, 0.01964579890653848),\n",
            " (314, 0.030389776867430694),\n",
            " (315, 0.034492684427856315),\n",
            " (316, 0.005600109866957533),\n",
            " (317, 0.03442444717896831),\n",
            " (318, 0.017843372815092993),\n",
            " (319, 0.014974307058898262),\n",
            " (320, 0.059011345832438944),\n",
            " (321, 0.02704282210373398),\n",
            " (322, 0.0066512282193086116),\n",
            " (323, 0.058654978227425),\n",
            " (324, 0.029361900680734593),\n",
            " (325, 0.04629447674667579),\n",
            " (326, 0.011040025664197593),\n",
            " (327, 0.00635166053512833),\n",
            " (328, 0.015260709369598622),\n",
            " (329, 0.021606330011331547),\n",
            " (330, 0.016820631431905552),\n",
            " (331, 0.005914950562459972),\n",
            " (332, 0.01118377008376023),\n",
            " (333, 0.03721789724985936),\n",
            " (334, 0.02793500898388258),\n",
            " (335, 0.013632595158742374),\n",
            " (336, 0.036102241723753016),\n",
            " (337, 0.019022144931550362),\n",
            " (338, 0.022110476690149893),\n",
            " (339, 0.016580197020705605),\n",
            " (340, 0.034132642017218336),\n",
            " (341, 0.01700118081797451),\n",
            " (342, 0.03059462192101937),\n",
            " (343, 0.02247229117088472),\n",
            " (344, 0.03387319260199469),\n",
            " (345, 0.11707006067243282),\n",
            " (346, 0.02565928651875511),\n",
            " (347, 0.033704935625100255),\n",
            " (348, 0.025119431751256634),\n",
            " (349, 0.0432768799073302),\n",
            " (350, 0.016094940240438057),\n",
            " (351, 0.03431056976397554),\n",
            " (352, 0.019097408242142566),\n",
            " (353, 0.01493003897187619),\n",
            " (354, 0.014655405478258712),\n",
            " (355, 0.01591740122851175),\n",
            " (356, 0.012382869432753563),\n",
            " (357, 0.054494511860472265),\n",
            " (358, 0.037973022060680546),\n",
            " (359, 0.029314564043175183),\n",
            " (360, 0.018038770696899954),\n",
            " (361, 0.030994538279279026),\n",
            " (362, 0.014751535259204272),\n",
            " (363, 0.008327302241188873),\n",
            " (364, 0.009322799973893903),\n",
            " (365, 0.011138637825126255),\n",
            " (366, 0.016610781106049008),\n",
            " (367, 0.007359153277359562),\n",
            " (368, 0.010873139690843688),\n",
            " (369, 0.013171746068554443),\n",
            " (370, 0.05684796622211675),\n",
            " (371, 0.031952259091720385),\n",
            " (372, 0.030109057522710318),\n",
            " (373, 0.017528287942317027),\n",
            " (374, 0.019405459606097047),\n",
            " (375, 0.016610781106049008),\n",
            " (376, 0.024512617268301867),\n",
            " (377, 0.012537932282605477),\n",
            " (378, 0.044790116915628564),\n",
            " (379, 0.007005022495130176),\n",
            " (380, 0.038056924198546616),\n",
            " (381, 0.03038382643564956),\n",
            " (382, 0.16871661046822137),\n",
            " (383, 0.03866585229494024),\n",
            " (384, 0.020094551084286455),\n",
            " (385, 0.030484934985635287)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model=gensim.models.LdaMulticore(bow_corpus,num_topics=10,id2word=dictionary,passes=2,workers=2)"
      ],
      "metadata": {
        "id": "1P5QSgPuSTyD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id,topic in lda_model.print_topics(-1):\n",
        "    print(id,'\\n', topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo77-KyiST05",
        "outputId": "6d6e46c2-4d27-40ac-9fd9-578fd97b4191"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            " 0.016*\"loss\" + 0.008*\"convex\" + 0.007*\"theorem\" + 0.006*\"cost\" + 0.006*\"rank\" + 0.006*\"dataset\" + 0.005*\"risk\" + 0.005*\"classif\" + 0.005*\"regular\" + 0.005*\"gradient\"\n",
            "1 \n",
            " 0.019*\"imag\" + 0.011*\"label\" + 0.008*\"layer\" + 0.007*\"activ\" + 0.005*\"unit\" + 0.005*\"mixtur\" + 0.005*\"region\" + 0.004*\"visual\" + 0.004*\"classifi\" + 0.004*\"classif\"\n",
            "2 \n",
            " 0.016*\"imag\" + 0.013*\"layer\" + 0.007*\"deep\" + 0.007*\"dataset\" + 0.007*\"convolut\" + 0.006*\"gradient\" + 0.005*\"recognit\" + 0.005*\"classif\" + 0.005*\"arxiv\" + 0.004*\"loss\"\n",
            "3 \n",
            " 0.015*\"kernel\" + 0.009*\"imag\" + 0.006*\"theorem\" + 0.006*\"rank\" + 0.006*\"dataset\" + 0.005*\"label\" + 0.005*\"cluster\" + 0.005*\"distanc\" + 0.004*\"convex\" + 0.004*\"norm\"\n",
            "4 \n",
            " 0.011*\"node\" + 0.010*\"tree\" + 0.007*\"graph\" + 0.006*\"word\" + 0.006*\"infer\" + 0.005*\"dataset\" + 0.005*\"sequenc\" + 0.005*\"imag\" + 0.005*\"cluster\" + 0.004*\"edg\"\n",
            "5 \n",
            " 0.011*\"infer\" + 0.008*\"variat\" + 0.007*\"prior\" + 0.005*\"likelihood\" + 0.005*\"posterior\" + 0.005*\"cluster\" + 0.004*\"spars\" + 0.004*\"node\" + 0.004*\"signal\" + 0.004*\"word\"\n",
            "6 \n",
            " 0.007*\"norm\" + 0.006*\"label\" + 0.006*\"nois\" + 0.005*\"theorem\" + 0.005*\"convex\" + 0.004*\"classif\" + 0.004*\"domain\" + 0.004*\"kernel\" + 0.004*\"spars\" + 0.004*\"smooth\"\n",
            "7 \n",
            " 0.014*\"neuron\" + 0.009*\"spike\" + 0.008*\"imag\" + 0.007*\"activ\" + 0.006*\"cell\" + 0.006*\"dynam\" + 0.005*\"signal\" + 0.005*\"respons\" + 0.005*\"unit\" + 0.005*\"cluster\"\n",
            "8 \n",
            " 0.012*\"graph\" + 0.011*\"cluster\" + 0.008*\"kernel\" + 0.007*\"theorem\" + 0.007*\"gradient\" + 0.005*\"label\" + 0.004*\"rank\" + 0.004*\"submodular\" + 0.003*\"nois\" + 0.003*\"polici\"\n",
            "9 \n",
            " 0.018*\"polici\" + 0.014*\"action\" + 0.009*\"reward\" + 0.006*\"agent\" + 0.006*\"game\" + 0.006*\"theorem\" + 0.005*\"regret\" + 0.005*\"gradient\" + 0.005*\"unit\" + 0.005*\"player\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_tfidf=gensim.models.LdaMulticore(corpus_tfidf,num_topics=10,id2word=dictionary,passes=2,workers=2)"
      ],
      "metadata": {
        "id": "9bjTRNdOST3w"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print(id,'\\n', topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXPNb-yST7L",
        "outputId": "f563a935-7710-47d0-bc2e-41af87b383d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            " 0.009*\"polici\" + 0.006*\"regret\" + 0.005*\"reward\" + 0.005*\"agent\" + 0.005*\"action\" + 0.003*\"reinforc\" + 0.003*\"convex\" + 0.002*\"submodular\" + 0.002*\"game\" + 0.002*\"loss\"\n",
            "1 \n",
            " 0.003*\"posterior\" + 0.002*\"node\" + 0.002*\"tree\" + 0.002*\"topic\" + 0.002*\"layer\" + 0.002*\"imag\" + 0.002*\"bayesian\" + 0.002*\"hidden\" + 0.002*\"infer\" + 0.002*\"mixtur\"\n",
            "2 \n",
            " 0.004*\"neuron\" + 0.003*\"spike\" + 0.003*\"stimulus\" + 0.002*\"graph\" + 0.002*\"cluster\" + 0.002*\"synapt\" + 0.002*\"node\" + 0.002*\"activ\" + 0.002*\"boost\" + 0.001*\"brain\"\n",
            "3 \n",
            " 0.008*\"regret\" + 0.008*\"bandit\" + 0.008*\"polici\" + 0.005*\"reward\" + 0.005*\"arm\" + 0.004*\"action\" + 0.002*\"player\" + 0.002*\"item\" + 0.002*\"game\" + 0.002*\"node\"\n",
            "4 \n",
            " 0.005*\"dropout\" + 0.003*\"privaci\" + 0.002*\"imag\" + 0.002*\"privat\" + 0.002*\"kernel\" + 0.002*\"queri\" + 0.002*\"node\" + 0.002*\"layer\" + 0.001*\"label\" + 0.001*\"neuron\"\n",
            "5 \n",
            " 0.004*\"cluster\" + 0.004*\"node\" + 0.003*\"topic\" + 0.003*\"graph\" + 0.003*\"polici\" + 0.002*\"infer\" + 0.002*\"belief\" + 0.002*\"posterior\" + 0.002*\"document\" + 0.002*\"latent\"\n",
            "6 \n",
            " 0.003*\"tree\" + 0.003*\"cluster\" + 0.003*\"node\" + 0.002*\"graph\" + 0.002*\"lift\" + 0.002*\"infer\" + 0.002*\"theorem\" + 0.001*\"polici\" + 0.001*\"processor\" + 0.001*\"path\"\n",
            "7 \n",
            " 0.006*\"neuron\" + 0.005*\"imag\" + 0.004*\"spike\" + 0.004*\"layer\" + 0.003*\"cell\" + 0.003*\"stimulus\" + 0.002*\"visual\" + 0.002*\"kernel\" + 0.002*\"segment\" + 0.002*\"circuit\"\n",
            "8 \n",
            " 0.002*\"cluster\" + 0.002*\"imag\" + 0.002*\"rank\" + 0.002*\"convex\" + 0.002*\"latent\" + 0.002*\"kernel\" + 0.001*\"proxim\" + 0.001*\"score\" + 0.001*\"admm\" + 0.001*\"layer\"\n",
            "9 \n",
            " 0.004*\"kernel\" + 0.003*\"rank\" + 0.003*\"convex\" + 0.002*\"cluster\" + 0.002*\"label\" + 0.002*\"loss\" + 0.002*\"theorem\" + 0.002*\"graph\" + 0.002*\"gradient\" + 0.002*\"dataset\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id, score in sorted(lda_model[bow_corpus[4310]],key=lambda tup:-1*tup[1]):\n",
        "    print(score,'\\n',lda_model.print_topic(id,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilrHps_NSm98",
        "outputId": "723d8eb3-708c-4a62-cad8-e9513bb75b9c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.99909526 \n",
            " 0.016*\"loss\" + 0.008*\"convex\" + 0.007*\"theorem\" + 0.006*\"cost\" + 0.006*\"rank\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id , score in sorted(lda_model_tfidf[bow_corpus[4310]],key=lambda tup: -1*tup[1]):\n",
        "    print(score, '\\n', lda_model_tfidf.print_topic(id,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_GOev0LSnAr",
        "outputId": "1e13a41f-7036-49a8-e73a-7d0ae43dd178"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9969067 \n",
            " 0.004*\"kernel\" + 0.003*\"rank\" + 0.003*\"convex\" + 0.002*\"cluster\" + 0.002*\"label\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unseen='How a Pentagon deal became an identity crisis for Google'\n",
        "bow=dictionary.doc2bow(process(unseen))\n",
        "\n",
        "for id, score in sorted(lda_model_tfidf[bow],key=lambda tup: -1*tup[1]):\n",
        "    print(score,'\\n',lda_model_tfidf.print_topic(id,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxT4zUoHSnDK",
        "outputId": "ecfa1016-0de9-4316-f452-9beec2a01cb1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8199646 \n",
            " 0.004*\"cluster\" + 0.004*\"node\" + 0.003*\"topic\" + 0.003*\"graph\" + 0.003*\"polici\"\n",
            "0.020008791 \n",
            " 0.004*\"kernel\" + 0.003*\"rank\" + 0.003*\"convex\" + 0.002*\"cluster\" + 0.002*\"label\"\n",
            "0.020005386 \n",
            " 0.009*\"polici\" + 0.006*\"regret\" + 0.005*\"reward\" + 0.005*\"agent\" + 0.005*\"action\"\n",
            "0.020005025 \n",
            " 0.006*\"neuron\" + 0.005*\"imag\" + 0.004*\"spike\" + 0.004*\"layer\" + 0.003*\"cell\"\n",
            "0.020003727 \n",
            " 0.003*\"posterior\" + 0.002*\"node\" + 0.002*\"tree\" + 0.002*\"topic\" + 0.002*\"layer\"\n",
            "0.020003248 \n",
            " 0.004*\"neuron\" + 0.003*\"spike\" + 0.003*\"stimulus\" + 0.002*\"graph\" + 0.002*\"cluster\"\n",
            "0.020002436 \n",
            " 0.008*\"regret\" + 0.008*\"bandit\" + 0.008*\"polici\" + 0.005*\"reward\" + 0.005*\"arm\"\n",
            "0.020002376 \n",
            " 0.005*\"dropout\" + 0.003*\"privaci\" + 0.002*\"imag\" + 0.002*\"privat\" + 0.002*\"kernel\"\n",
            "0.020002294 \n",
            " 0.003*\"tree\" + 0.003*\"cluster\" + 0.003*\"node\" + 0.002*\"graph\" + 0.002*\"lift\"\n",
            "0.02000216 \n",
            " 0.002*\"cluster\" + 0.002*\"imag\" + 0.002*\"rank\" + 0.002*\"convex\" + 0.002*\"latent\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsa_model=gensim.models.LsiModel(bow_corpus,num_topics=10,id2word=dictionary)"
      ],
      "metadata": {
        "id": "ImtXOQ9hSnF3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id,topic in lsa_model.print_topics(-1):\n",
        "    print(id,'\\n',topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xa5ASklSnJW",
        "outputId": "74984c78-8a2b-4f47-e967-16b29a54eafa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            " 0.322*\"imag\" + 0.175*\"label\" + 0.158*\"cluster\" + 0.155*\"kernel\" + 0.136*\"dataset\" + 0.131*\"graph\" + 0.126*\"layer\" + 0.119*\"infer\" + 0.116*\"loss\" + 0.112*\"node\"\n",
            "1 \n",
            " 0.709*\"imag\" + -0.201*\"polici\" + -0.151*\"graph\" + -0.144*\"theorem\" + -0.144*\"cluster\" + 0.138*\"layer\" + -0.129*\"action\" + -0.119*\"node\" + 0.107*\"visual\" + -0.104*\"reward\"\n",
            "2 \n",
            " 0.448*\"cluster\" + -0.322*\"neuron\" + -0.273*\"polici\" + 0.232*\"graph\" + 0.216*\"label\" + -0.213*\"action\" + 0.194*\"kernel\" + -0.190*\"spike\" + -0.157*\"agent\" + -0.155*\"reward\"\n",
            "3 \n",
            " 0.427*\"neuron\" + -0.331*\"polici\" + 0.328*\"cluster\" + 0.284*\"spike\" + -0.246*\"imag\" + -0.225*\"action\" + -0.166*\"agent\" + -0.153*\"reward\" + 0.140*\"stimulus\" + 0.139*\"activ\"\n",
            "4 \n",
            " 0.559*\"cluster\" + -0.514*\"kernel\" + 0.219*\"polici\" + -0.182*\"loss\" + 0.171*\"action\" + 0.145*\"agent\" + 0.142*\"imag\" + 0.133*\"node\" + -0.126*\"convex\" + 0.122*\"graph\"\n",
            "5 \n",
            " -0.603*\"kernel\" + -0.375*\"cluster\" + 0.367*\"label\" + 0.226*\"node\" + -0.214*\"polici\" + 0.162*\"tree\" + 0.156*\"graph\" + -0.142*\"imag\" + -0.130*\"action\" + 0.118*\"word\"\n",
            "6 \n",
            " 0.426*\"graph\" + 0.415*\"kernel\" + 0.360*\"node\" + -0.308*\"cluster\" + -0.242*\"loss\" + 0.233*\"tree\" + -0.195*\"convex\" + -0.172*\"rank\" + -0.150*\"gradient\" + 0.148*\"edg\"\n",
            "7 \n",
            " 0.648*\"label\" + 0.190*\"classifi\" + 0.165*\"neuron\" + -0.160*\"gradient\" + -0.150*\"graph\" + -0.150*\"infer\" + -0.147*\"node\" + 0.142*\"cluster\" + 0.141*\"classif\" + 0.136*\"kernel\"\n",
            "8 \n",
            " 0.358*\"word\" + 0.320*\"topic\" + -0.301*\"graph\" + 0.219*\"infer\" + -0.210*\"imag\" + -0.185*\"loss\" + 0.182*\"document\" + -0.160*\"convex\" + 0.156*\"latent\" + 0.151*\"posterior\"\n",
            "9 \n",
            " 0.639*\"layer\" + 0.269*\"unit\" + -0.226*\"imag\" + 0.203*\"deep\" + -0.164*\"infer\" + 0.158*\"hidden\" + -0.150*\"prior\" + 0.148*\"convolut\" + 0.133*\"architectur\" + -0.132*\"spike\"\n"
          ]
        }
      ]
    }
  ]
}